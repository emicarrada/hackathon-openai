# Smart Optimizer - Hackathon OpenAI 2025

## ğŸ¯ DescripciÃ³n
**Sistema con AUTOMEJORA REAL** para Hackathon Kavak x OpenAI MÃ©xico 2025.

Diferenciador clave: **Ãšnico sistema que aprende de cada ejecuciÃ³n**
- Run 1: Usa modelo caro (GPT-4o) â†’ Auditor detecta desperdicio
- Memoria se actualiza con estrategia optimizada
- Run 2: Usa modelo barato (GPT-3.5-turbo) â†’ **87% de ahorro**

## ğŸš€ InstalaciÃ³n RÃ¡pida

```bash
# 1. Clonar repositorio
git clone <repo-url>
cd hackathon-openai

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar API Key
cp env.template .env
# Editar .env y aÃ±adir tu OPENAI_API_KEY

# 4. Ejecutar demo
export $(cat .env | xargs)
python demo_hackathon.py
```

## ğŸ—ï¸ Arquitectura - 6 Nodos con Automejora

Sistema completo con feedback loop persistente:

```
1. recibir_tarea      â†’ Clasifica tipo de tarea (resumen, traducciÃ³n, etc.)
2. consultar_memoria  â†’ Busca estrategia aprendida en JSON
3. ejecutar_tarea     â†’ Ejecuta con modelo seleccionado
4. evaluar_contador   â†’ Captura mÃ©tricas (tokens, latencia)
5. auditor_feedback   â†’ LLM-CrÃ­tico analiza eficiencia
6. actualizar_memoria â†’ Guarda estrategia optimizada
```

### Flujo de Automejora

```
RUN 1 (Inocente):
  Usuario: "Resume este artÃ­culo"
  â†’ Sin estrategia â†’ Usa GPT-4o (default caro)
  â†’ 128 tokens consumidos
  â†’ Auditor detecta: "Tarea simple no necesita GPT-4o"
  â†’ Memoria actualizada: {resumen: gpt-3.5-turbo}

RUN 2 (Inteligente):
  Usuario: "Resume este otro artÃ­culo"
  â†’ Estrategia encontrada â†’ Usa GPT-3.5-turbo
  â†’ 155 tokens pero modelo 10x mÃ¡s barato
  â†’ Ahorro real en costos de API
```

## ğŸ“ Estructura del Proyecto

```
hackathon-openai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agente.py              # Orquestador LangGraph (6 nodos)
â”‚   â”œâ”€â”€ memoria.py             # Persistencia de estrategias
â”‚   â”œâ”€â”€ utils.py               # Utilidades generales
â”‚   â””â”€â”€ nodos/
â”‚       â”œâ”€â”€ recibir_tarea.py
â”‚       â”œâ”€â”€ consultar_memoria.py
â”‚       â”œâ”€â”€ ejecutar_tarea.py
â”‚       â”œâ”€â”€ evaluar_contador.py
â”‚       â”œâ”€â”€ auditor_feedback.py
â”‚       â””â”€â”€ actualizar_memoria.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ estrategias.json       # Memoria persistente (JSON)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AUTOMEJORA_Y_RUBRICA.md    # ExplicaciÃ³n tÃ©cnica
â”‚   â””â”€â”€ Diagrama_Sistema_Completo.tex  # Diagrama LaTeX
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_nodos.py
â”‚   â”œâ”€â”€ test_contador.py
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ demo_hackathon.py          # Script de presentaciÃ³n
â””â”€â”€ requirements.txt
```

## ğŸ¬ Demo para PresentaciÃ³n

```bash
# Demo completa (2-3 minutos)
python demo_hackathon.py

# Demo rÃ¡pida (30 segundos)
python demo_hackathon.py --rapida
```

### Salida Esperada

```
ğŸ¬ DEMO PARA HACKATHON: Run 1 vs Run 2
======================================================================

â–¶ï¸  RUN 1 - SISTEMA INOCENTE (Sin estrategia)
   Modelo usado: gpt-4o
   Tokens consumidos: 128
   ğŸ” Auditor detectÃ³ ineficiencia
   ğŸ’¾ Memoria actualizada

â–¶ï¸  RUN 2 - SISTEMA INTELIGENTE (Con estrategia aprendida)
   Modelo usado: gpt-3.5-turbo
   Tokens consumidos: 155
   
ğŸ¯ Ahorro conseguido:
   - Modelo 10x mÃ¡s barato
   - Escalable a millones de requests
   - Sin pÃ©rdida de calidad
```

## ğŸ† Puntos Clave para Jueces

### âœ… INNOVACIÃ“N (30 pts)
- **Ãšnico sistema con automejora REAL** en el hackathon
- Arquitectura 6 nodos con feedback loop persistente
- Auditor LLM que evalÃºa eficiencia automÃ¡ticamente

### âœ… IMPACTO (25 pts)
- 87% de ahorro en costos de API demostrado en vivo
- Escalable a millones de solicitudes (ahorro masivo)
- Aplicable a cualquier industria que use LLMs

### âœ… EJECUCIÃ“N (25 pts)
- Sistema funcional end-to-end
- LangGraph + OpenAI + Memoria persistente (JSON)
- Tests automatizados y documentaciÃ³n completa

### âœ… PRESENTACIÃ“N (20 pts)
- Demo clara y visual (Run 1 vs Run 2)
- Narrativa fuerte: "Sistema que aprende de sus errores"
- Diagrama LaTeX profesional del flujo

**ï¿½ TOTAL: 100/100 puntos posibles**

## ğŸ”§ Stack TÃ©cnico

- **LangGraph 0.0.40+**: OrquestaciÃ³n de nodos con StateGraph
- **OpenAI API**: GPT-4o, GPT-3.5-turbo, GPT-4o-mini
- **Python 3.10+**: Asyncio, typing, dataclasses
- **JSON**: Persistencia de memoria (data/estrategias.json)

## ğŸ“š DocumentaciÃ³n Adicional

- **`docs/AUTOMEJORA_Y_RUBRICA.md`**: ExplicaciÃ³n tÃ©cnica completa + mapeo a rÃºbrica
- **`docs/Diagrama_Sistema_Completo.tex`**: Diagrama LaTeX para presentaciÃ³n
- **`METRICAS_PROPUESTAS.md`**: 30+ mÃ©tricas avanzadas para extensiones futuras

## ğŸ‘¥ Equipo

- **Brandon**: Nodo Evaluador + Tests
- **Israel**: Nodo Generador + IntegraciÃ³n
- **Cristopher**: Nodo Validador + Memoria
- **Emiliano (Carrada)**: Arquitectura + OrquestaciÃ³n

## ğŸ“„ Licencia

Proyecto para Hackathon OpenAI 2025 - Kavak x OpenAI MÃ©xico
