\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{geometry}
\geometry{margin=1in}

\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    breaklines=true,
    captionpos=b
}

\title{Plan de Acción para Usar Agentes de IA en el Hackathon}
\author{Hackathon OpenAI - Smart Optimizer}
\date{22 de octubre de 2025}

\begin{document}

\maketitle

\section{Introducción}

Durante el hackathon, cada miembro del equipo usará agentes de IA (como GitHub Copilot, ChatGPT o Claude) para acelerar la implementación. El objetivo es generar código de alta calidad sin alucinaciones, enfocándonos en precisión, compatibilidad con LangGraph y cumplimiento de reglas.

\section{Plan General de Acción}

\begin{enumerate}
    \item \textbf{Proporciona Contexto Completo}: Antes de pedir código, pega el pseudocódigo relevante, estructura del proyecto y requisitos (ej: "Implementa basado en este pseudocódigo, usando openai library").
    
    \item \textbf{Itera y Valida}: Pide al agente que genere código, luego revísalo manualmente. Si hay errores, pide correcciones específicas (ej: "Arregla el manejo de errores").
    
    \item \textbf{Evita Alucinaciones}: Usa prompts específicos, limita scope (ej: "No inventes APIs, usa solo openai oficial"). Pide explicaciones: "¿Por qué este código funciona?".
    
    \item \textbf{Mejores Prácticas}:
    \begin{itemize}
        \item Código modular, comentado.
        \item Pruebas unitarias después de cada función.
        \item Compatibilidad: Retorna dicts para LangGraph.
        \item Seguridad: No hardcode keys; usa os.getenv.
    \end{itemize}
    
    \item \textbf{Herramientas Recomendadas}: GitHub Copilot para autocompletado en VS Code; ChatGPT para brainstorming.
    
    \item \textbf{Tiempo}: Dedica 10-15 min por prompt. Si el agente falla, implementa manualmente.
\end{enumerate}

\section{Prompts Específicos por Rol}

\subsection{Para Brandon Vilchis (Evaluador - Spoke1)}

\textbf{Prompt Base}: \\
"Actúa como un desarrollador experto en Python. Implementa la función \texttt{evaluar\_complejidad(tarea: str) -> dict} basada en este pseudocódigo [pega pseudocódigo]. Usa la biblioteca \texttt{openai} para cualquier llamada API, pero en este caso no es necesario. El output debe ser un dict con 'complejidad' ('baja', 'media', 'alta'), 'factores' (longitud, keywords). Asegura que sea compatible con LangGraph. Evita alucinaciones: no inventes funciones inexistentes. Explica cada línea. Código final debe ser ejecutable y sin errores."

\textbf{Plan de Acción}:
\begin{itemize}
    \item Pega el pseudocódigo del setup.
    \item Pide implementación paso a paso.
    \item Valida: Prueba con "Hola" (baja) y "Explica relatividad" (alta).
    \item Si alucina, agrega: "Usa solo lógica condicional simple, no ML avanzado."
\end{itemize}

\subsection{Para Israel Cabrera (Generador/Refinador - Spoke2)}

\textbf{Prompt Base}: \\
"Como experto en IA, implementa \texttt{generar\_refinar(tarea: str, complejidad: str) -> str} usando Self-Refine con un solo LLM. Basado en este pseudocódigo [pega pseudocódigo]. Usa \texttt{openai.OpenAI} para llamadas. Modelo: 'gpt-3.5-turbo' si complejidad=='baja', else 'gpt-4'. Limita tokens a 500. Retorna string refinado. Evita alucinaciones: No uses APIs inventadas. Explica el loop de Self-Refine. Código debe manejar errores (try-except) y ser eficiente."

\textbf{Plan de Acción}:
\begin{itemize}
    \item Proporciona contexto de Self-Refine.
    \item Pide generación inicial + refinamiento.
    \item Testea: Input "Suma 2+2", output mejorado.
    \item Corrección: Si alucina, especifica "Usa solo chat completions, no embeddings."
\end{itemize}

\subsection{Para Cristopher Carrada (Validador/Tester - Hub)}

\textbf{Prompt Base}: \\
"Experto en testing, implementa \texttt{validar\_calidad(output\_gpt35: str, output\_gpt4: str, tarea: str) -> dict} usando un Juez LLM. Pseudocódigo [pega]. Usa \texttt{openai} para juicio objetivo. Prompt al juez: 'Compara outputs para [tarea]: GPT-3.5: [output35], GPT-4: [output4]. ¿Cuál mejor? Razón.' Parsea respuesta para 'mejor\_modelo'. Agrega métricas simples (ej: len(output)). Compatible con LangGraph. Sin alucinaciones: Solo lógica de comparación. Explica parsing."

\textbf{Plan de Acción}:
\begin{itemize}
    \item Enfócate en Juez LLM primero.
    \item Luego, integra testing end-to-end.
    \item Valida: Compara outputs reales, mide mejora.
    \item Si falla, pide: "Simplifica parsing a string matching."
\end{itemize}

\section{Checklist Final}

\begin{itemize}
    \item [ ] Proporciona contexto antes de prompts.
    \item [ ] Revisa código generado (no copies ciegamente).
    \item [ ] Prueba en entorno real.
    \item [ ] Si alucina, refina prompt con más detalles.
    \item [ ] Comparte código con el hub para integración.
\end{itemize}

Este plan asegura código de alta calidad y eficiencia. ¡Usen agentes como asistentes, no como reemplazos!

\end{document}